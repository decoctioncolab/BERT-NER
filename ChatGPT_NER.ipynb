{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Zero-Shot NER using OpenAI ChatGPT, Python and Streamlit"
      ],
      "metadata": {
        "id": "Z8XhvOy4oS3C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install `openai` and `streamlit` python packages"
      ],
      "metadata": {
        "id": "EJajvmFBoaqy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade openai\n",
        "!pip install -q streamlit"
      ],
      "metadata": {
        "id": "q3zfMNLnMjiG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae3fa5eb-a1c7-458a-ea36-d444534e4650"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.2-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.1/70.1 KB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.9/dist-packages (from openai) (2.25.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai) (4.65.0)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (22.2.0)\n",
            "Collecting charset-normalizer<4.0,>=2.0\n",
            "  Downloading charset_normalizer-3.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 KB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Installing collected packages: multidict, frozenlist, charset-normalizer, async-timeout, yarl, aiosignal, aiohttp, openai\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 charset-normalizer-3.1.0 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.2 yarl-1.8.2\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m73.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.6/80.6 KB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 KB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.8/164.8 KB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.7/238.7 KB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 KB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for validators (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.9.0 requires jedi>=0.10, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup Ngrok in colab"
      ],
      "metadata": {
        "id": "8FbRB_T1osDI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download ngrok linux package"
      ],
      "metadata": {
        "id": "1ZEitIQXo5N_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://bin.equinox.io/c/bNyj1mQVY4c/ngrok-v3-stable-linux-386.tgz"
      ],
      "metadata": {
        "id": "E5uSpHydokiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extract the package"
      ],
      "metadata": {
        "id": "c3u5hR29o-NU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xvf ngrok-v3-stable-linux-386.tgz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac6DkzSBpEwZ",
        "outputId": "6148f380-7e9c-42f1-bd5c-703d988d7fe9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ngrok\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Autheticate ngrok with token\n",
        "[ngrok auth token](https://dashboard.ngrok.com/get-started/your-authtoken)"
      ],
      "metadata": {
        "id": "CiXukWMRpKIZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!./ngrok config add-authtoken your_ngrok_authetication_token"
      ],
      "metadata": {
        "id": "SoDOsjhRpNDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install pyngrok"
      ],
      "metadata": {
        "id": "izWu8wQLpU5h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok"
      ],
      "metadata": {
        "id": "LI3L5MKSpUsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tunnel from Google Colab to ngrok"
      ],
      "metadata": {
        "id": "3-JrTYsSpZrT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok \n",
        "public_url = ngrok.connect(port='8501')\n",
        "public_url"
      ],
      "metadata": {
        "id": "i92jhFVHpUjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Write the whole code as a file for our NER streamlit application"
      ],
      "metadata": {
        "id": "ftiNg3Lupm74"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#%%writefile ner_streamlit_app.py \n",
        "import streamlit as st\n",
        "import openai\n",
        "import os\n",
        "import re\n",
        "import ast\n",
        "\n",
        "openai.api_key= \"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\"\n",
        "#openai.api_key = \"OPENAI_API_KEY\"\n",
        "\n",
        "SYSTEM_PROMPT = \"You are a smart and intelligent Named Entity Recognition (NER) system. I will provide you the definition of the entities you need to extract, the sentence from where your extract the entities and the output format with examples.\"\n",
        "\n",
        "USER_PROMPT_1 = \"Are you clear about your role?\"\n",
        "\n",
        "ASSISTANT_PROMPT_1 = \"Sure, I'm ready to help you with your NER task. Please provide me with the necessary information to get started.\"\n",
        "\n",
        "GUIDELINES_PROMPT = (\n",
        "    \"Entity Definition:\\n\"\n",
        "    \"1. PERSON: Short name or full name of a person from any geographic regions.\\n\"\n",
        "    \"2. DATE: Any format of dates. Dates can also be in natural language.\\n\"\n",
        "    \"3. LOC: Name of any geographic location, like cities, countries, continents, districts etc.\\n\"\n",
        "    \"\\n\"\n",
        "    \"Output Format:\\n\"\n",
        "    \"{{'PERSON': [list of entities present], 'DATE': [list of entities present], 'LOC': [list of entities present]}}\\n\"\n",
        "    \"If no entities are presented in any categories keep it None\\n\"\n",
        "    \"\\n\"\n",
        "    \"Examples:\\n\"\n",
        "    \"\\n\"\n",
        "    \"1. Sentence: Mr. Jacob lives in Madrid since 12th January 2015.\\n\"\n",
        "    \"Output: {{'PERSON': ['Mr. Jacob'], 'DATE': ['12th January 2015'], 'LOC': ['Madrid']}}\\n\"\n",
        "    \"\\n\"\n",
        "    \"2. Sentence: Mr. Rajeev Mishra and Sunita Roy are friends and they meet each other on 24/03/1998.\\n\"\n",
        "    \"Output: {{'PERSON': ['Mr. Rajeev Mishra', 'Sunita Roy'], 'DATE': ['24/03/1998'], 'LOC': ['None']}}\\n\"\n",
        "    \"\\n\"\n",
        "    \"3. Sentence: {}\\n\"\n",
        "    \"Output: \"\n",
        ")\n",
        "\n",
        "COLORED_ENTITY = {\"PERSON\": \"red\", \"DATE\": \"blue\", \"LOC\": \"green\"}\n",
        "\n",
        "\n",
        "def openai_chat_completion_response(final_prompt):\n",
        "  response = openai.ChatCompletion.create(\n",
        "              model=\"gpt-3.5-turbo\",\n",
        "              messages=[\n",
        "                    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "                    {\"role\": \"user\", \"content\": USER_PROMPT_1},\n",
        "                    {\"role\": \"assistant\", \"content\": ASSISTANT_PROMPT_1},\n",
        "                    {\"role\": \"user\", \"content\": final_prompt}\n",
        "                ]\n",
        "            )\n",
        "\n",
        "  return response['choices'][0]['message']['content'].strip(\" \\n\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rGKKsQc7pUOY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_sentence = \"Hanyu Pinyin worked under Christopher in the same project for 2 years and the project started on 24-06-2018.\"\n",
        "GUIDELINES_PROMPT = GUIDELINES_PROMPT.format(my_sentence)\n",
        "ners = openai_chat_completion_response(GUIDELINES_PROMPT)\n",
        "print(ners)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-p_jD7cue5tc",
        "outputId": "07547ef1-7f7a-4523-aac3-1ac762944222"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'PERSON': ['Hanyu Pinyin', 'Christopher'], 'DATE': ['24-06-2018', '2 years'], 'LOC': ['None']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M5bVACHJj1Jl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xYjAMubSj0xC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cb0fnvuMj0df"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_sentence = st.text_input('Your Sentence')\n",
        "if st.button('Submit'):\n",
        "  GUIDELINES_PROMPT = GUIDELINES_PROMPT.format(my_sentence)\n",
        "  ners = openai_chat_completion_response(GUIDELINES_PROMPT)\n",
        "  ners_dictionary = ast.literal_eval(ners)\n",
        "  for entity_type, entity_list in ners_dictionary.items():\n",
        "    entity_list = list(set(entity_list))\n",
        "    for ent in entity_list:\n",
        "      if ent != 'None':\n",
        "        my_sentence = re.sub(ent, \":\"+COLORED_ENTITY[entity_type]+\"[\"+ent+\"\\[\"+entity_type+\"\\]\"+\"]\", my_sentence)\n",
        "  st.markdown(my_sentence)"
      ],
      "metadata": {
        "id": "effLziuvepEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run the streamlit app"
      ],
      "metadata": {
        "id": "NTZIhdq5p6yI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run ./ner_streamlit_app.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "id": "jKWk4epTT0-q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f1bbc1f-7df3-4da9-fdb4-88fa72281b3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: streamlit: command not found\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 3.338s\n",
            "your url is: https://clever-tables-end-35-185-252-232.loca.lt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LbTFtZcNhx6F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}